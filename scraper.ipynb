{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Python libraries for data and visualisation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as ply\n",
    "import os\n",
    "\n",
    "#Web scraping libraries\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from IPython.core.display import HTML\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Report extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_table(link_string):\n",
    "    req = requests.get(link_string)\n",
    "    \n",
    "    html = req.text\n",
    "    \n",
    "    # extract first table in the page\n",
    "    start = html.index('<table')\n",
    "    end = html[start:].index('</table>') + start\n",
    "    \n",
    "    table = html[start:end]\n",
    "    \n",
    "    return table\n",
    "        \n",
    "def get_report_links(table):\n",
    "    contain_links = [cl.group() for cl in list(re.finditer('<td class=\"left group_start\".*</a></td>', table))]\n",
    "    \n",
    "    links = []\n",
    "    \n",
    "    for cl in contain_links:\n",
    "\n",
    "        link = re.search('href=\".*\"', cl).group().replace('href=', '').replace('\"', '')\n",
    "        \n",
    "        link = 'https://fbref.com' + link\n",
    "        \n",
    "        links.append(link)\n",
    "    \n",
    "    # for some reason there are two of each.\n",
    "    return links[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shot Table Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_timestamp(html):\n",
    "    date = re.search('data-venue-date=\"[^\"]*\"', html)\\\n",
    "            .group()\\\n",
    "            .replace('data-venue-date=', '')\\\n",
    "            .replace('\"', '')\n",
    "    time = re.search('data-venue-time=\"[^\"]*\"', html)\\\n",
    "            .group()\\\n",
    "            .replace('data-venue-time=', '')\\\n",
    "            .replace('\"', '')\n",
    "    \n",
    "    timestamp = pd.to_datetime(date + ' ' + time)\n",
    "    \n",
    "    return timestamp\n",
    "\n",
    "def get_shot_table(link_string):\n",
    "    \n",
    "    req = requests.get(link_string)\n",
    "    print(req)\n",
    "    html = req.text\n",
    "    \n",
    "    timestamp = get_match_timestamp(html)\n",
    "    \n",
    "    # extract table with id 'shots_all'\n",
    "    start = re.search('<table .* id=\"shots_all\"', html).span()[0]\n",
    "    end = html[start:].index('</table>') + start\n",
    "    \n",
    "    table = html[start:end]\n",
    "    \n",
    "    return table, timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Season and Team Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get('https://fbref.com/en/comps/9/Premier-League-Stats#all_stats_shooting_squads').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = html.index('<table')\n",
    "end = html[start:].index('</table>') + start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = html[start: end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = re.findall('href=\"[^\"]*squads[^\"]*\"', table)\n",
    "props = np.asarray([l.replace('href=', '')\n",
    "                    .replace('\"', '')\n",
    "                    .replace('-Stats', '')\n",
    "                    .split('/') for l in links])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = props[:, 3]\n",
    "names = np.asarray([n.replace('-', ' ') for n in props[:, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = {'s10728':'2020-2021',\n",
    "          's3232':'2019-2020',\n",
    "          's1889':'2018-2019',\n",
    "          's1631':'2017-2018',\n",
    "          's1526':'2016-2017',\n",
    "          's1467':'2015-2016',\n",
    "          's733':'2014-2015'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "premier_league_link = 'https://fbref.com/en/squads/7c21e445/2014-2015/matchlogs/s733/shooting/West-Ham-United-Match-Logs-Premier-League'\n",
    "\n",
    "path = urlparse(premier_league_link).path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_links = []\n",
    "\n",
    "for k, v in seasons.items():\n",
    "    for n, i in zip(names, ids):\n",
    "        path[3] = i\n",
    "        path[4] = v\n",
    "        path[6] = k\n",
    "        path[8] = n.replace(' ', '-') + '-Match-Logs-Premier-League'\n",
    "        \n",
    "        team_links.append('/'.join(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_links = ['https://fbref.com' + tl for tl in team_links]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shot table to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shot_table_df(report_link):\n",
    "\n",
    "    table_html, timestamp = get_shot_table(report_link)\n",
    "\n",
    "    # gives a list of tables, only one table is given\n",
    "    table = pd.read_html(table_html)[0]\n",
    "\n",
    "    table.columns = [c[1] if 'Unnamed' in c[0] else c[0] + ' ' + c[1] for c in table.columns]\n",
    "\n",
    "    table = table.dropna(how='all')\n",
    "\n",
    "    # set minutes as ints\n",
    "    table['Minute'] = table['Minute'].astype(str)\n",
    "    table.loc[:, 'Minute'] = [minute_plus(m) for m in table['Minute']]\n",
    "    table['Minute'] = table['Minute'].astype(float).astype(int)\n",
    "\n",
    "    # opposite in match\n",
    "    map_ = table['Squad'].unique()\n",
    "    table['Against'] = [map_[int(o)] for o in ~(table['Squad'] == map_[1])]\n",
    "\n",
    "    cols = table.columns.tolist()\n",
    "\n",
    "    table = table[cols[:3] + cols[-1:] + cols[3:-1]]\n",
    "\n",
    "    table['Timestamp'] = [timestamp for i in table['Squad']]\n",
    "    \n",
    "    return table\n",
    "\n",
    "\n",
    "def extract_tables(team_link):\n",
    "    tables = []\n",
    "    event_dfs = []\n",
    "\n",
    "    match_table = get_match_table(team_link)\n",
    "\n",
    "    report_links = get_report_links(match_table)\n",
    "    \n",
    "    for rl in report_links:\n",
    "        table = get_shot_table_df(rl)\n",
    "        \n",
    "        tables.append(table)\n",
    "            \n",
    "    return tables, event_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Event Tables functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_get_lines(soup):\n",
    "\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # break into lines and remove leading and trailing space on each\n",
    "    lines = [line.strip() for line in text.splitlines()]\n",
    "    # break multi-headlines into a line each\n",
    "    chunks = [phrase.strip() for line in lines for phrase in line.split(\"  \")]\n",
    "    # remove empty elements\n",
    "    chunks = [chunk for chunk in chunks if len(chunk) > 0]\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def get_team_names(full_soup):\n",
    "    \n",
    "    lines = soup_get_lines(full_soup)\n",
    "    \n",
    "    return lines[1], lines[2]\n",
    "\n",
    "def event_to_list(event_soup, team_name, opponent_team, is_team_a):\n",
    "    # to list\n",
    "    event = soup_get_lines(event_soup)\n",
    "    # correct time\n",
    "    event[0] = event[0].replace('&rsquor;', '')\n",
    "    # correct event desc\n",
    "    event[-1] = event[-1].replace('â€”\\xa0', '')\n",
    "    # even out length of list\n",
    "    while len(event) < 6:\n",
    "        event.append(None)\n",
    "    # add team name\n",
    "    event.append(team_name)\n",
    "    # add opponent team name\n",
    "    event.append(opponent_team)\n",
    "    # set score to the difference in goals\n",
    "    a, b = event[1].split(':')[0], event[1].split(':')[-1]\n",
    "    dif = int(a) - int(b)\n",
    "    # in case of team a: goals_a - goals_b\n",
    "    event[1] = dif if is_team_a else -dif\n",
    "    \n",
    "    return event\n",
    "\n",
    "def list_events(link):\n",
    "    req = requests.get(link)\n",
    "    \n",
    "    print(req)\n",
    "    \n",
    "    html = req.text\n",
    "    \n",
    "    start = re.search('<div[\\\\s]+id=\"events_wrap\">', html).span()[0]\n",
    "    \n",
    "    end = re.search('<div[\\\\s]+id=\"team_stats\">', html).span()[0]\n",
    "    \n",
    "    all_events = html[start:end]\n",
    "    \n",
    "    full_soup = BeautifulSoup(all_events)\n",
    "    \n",
    "    team_a, team_b = get_team_names(full_soup)\n",
    "    \n",
    "    # extract team_a events\n",
    "    \n",
    "    a_soups = full_soup.findAll(\"div\", {\"class\": \"event a\"})\n",
    "    \n",
    "    a_events = [event_to_list(a_soup, team_a, team_b, True) for a_soup in a_soups]\n",
    "    \n",
    "    # extract team_b events\n",
    "    \n",
    "    b_soups = full_soup.findAll(\"div\", {\"class\": \"event b\"})\n",
    "    \n",
    "    b_events = [event_to_list(b_soup, team_b, team_a, False) for b_soup in b_soups]\n",
    "    \n",
    "    events = a_events + b_events\n",
    "    \n",
    "    return events, get_match_timestamp(html)\n",
    "\n",
    "def minute_plus(minute):\n",
    "    # to turn minute values with + to ints\n",
    "    # 100 is added to values greater than 45 to separate the first half\n",
    "    if '+' in minute:\n",
    "        ms = minute.split('+')\n",
    "\n",
    "        if int(float(ms[0])) > 45:\n",
    "            return int(float(ms[0])) + int(float(ms[1])) + 100\n",
    "        else:\n",
    "            return int(float(ms[0])) + int(float(ms[1]))\n",
    "    else:\n",
    "        if int(float(minute)) > 45:\n",
    "            return int(float(minute)) + 100\n",
    "        else:\n",
    "            return int(float(minute))\n",
    "\n",
    "def get_event_df(link):\n",
    "    \n",
    "    events, timestamp = list_events(link)    \n",
    "    \n",
    "    events_df = pd.DataFrame(events)\n",
    "    \n",
    "    # drop substitution rows\n",
    "    events_df = events_df[np.logical_not(['for ' in e for e in events_df[3]])].sort_values(0).reset_index(drop=True)\n",
    "    \n",
    "    # name columns\n",
    "    events_df.columns = ['Minute', 'Score', 'Player', 'Notes', 'SCA 1 Player', 'SCA 1 Event', 'Squad', 'Against']\n",
    "    \n",
    "    # set timestamp\n",
    "    events_df['Timestamp'] = timestamp\n",
    "    \n",
    "    # move 'assist' to SCA 1 Event\n",
    "    assists = events_df['Notes'] == 'Assist:'\n",
    "    events_df.loc[assists, 'Notes'] = events_df[assists]['SCA 1 Event']\n",
    "    events_df.loc[assists, 'SCA 1 Event'] = 'Assist'\n",
    "    \n",
    "    # set minutes as ints\n",
    "    events_df.loc[:, 'Minute'] = [minute_plus(m) for m in events_df.loc[:, 'Minute']]\n",
    "    events_df['Minute'] = events_df['Minute'].astype('int64')\n",
    "    \n",
    "    # add player advantage feature\n",
    "    events_df['Player Advantage'] = np.zeros(len(events_df))\n",
    "    red_cards = events_df[events_df['Notes'] == 'Red Card']\n",
    "    for i, red_card in red_cards.iterrows():\n",
    "        time = events_df['Minute'] >= red_card['Minute']\n",
    "        team = events_df['Squad'] == red_card['Squad']\n",
    "        events_df.loc[np.logical_and(time, team), 'Player Advantage'] -= 1\n",
    "        events_df.loc[np.logical_and(time, ~team), 'Player Advantage'] += 1\n",
    "    \n",
    "    return events_df.sort_values('Minute').reset_index(drop=True)\n",
    "\n",
    "def extract_team_event_dfs(team_link):\n",
    "    match_table = get_match_table(team_link)\n",
    "\n",
    "    report_links = get_report_links(match_table)\n",
    "\n",
    "    return pd.concat([get_event_df(rl) for rl in report_links], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Generating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_shooting_data(team_link):\n",
    "    match_table = get_match_table(team_link)\n",
    "\n",
    "    report_links = get_report_links(match_table)\n",
    "    \n",
    "    all_dfs = []\n",
    "    \n",
    "    for rl in report_links:\n",
    "        event_df = get_event_df(rl)\n",
    "        \n",
    "        shot_df = get_shot_table_df(rl)\n",
    "        \n",
    "        shot_df['Score'] = np.zeros(len(shot_df))\n",
    "        shot_df['Player Advantage'] = np.zeros(len(shot_df))\n",
    "        for i, event in event_df.iterrows():\n",
    "            time = shot_df['Minute'] >= event['Minute']\n",
    "            shot_df.loc[time, 'Score'] = event['Score']\n",
    "            shot_df.loc[time, 'Player Advantage'] = event['Player Advantage']\n",
    "            \n",
    "        all_dfs.append(shot_df)\n",
    "        \n",
    "    concat_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    \n",
    "    return concat_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
