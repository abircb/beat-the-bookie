{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP0036: Group Coursework \n",
    "\n",
    "### Introduction\n",
    "\n",
    "How does one ``beat the bookie``? In a game so seemingly complex, dominated by a combination of both skill and chance, predicting the outcomes of football matchs and making score predictions seems like an intractable task. On that note, however, the development of complex learning-based systems have allowed us to effectively explore this problem domain. Historically, many attempts have been made to predict the outcome of football matches by using the respective number of goals scored by each team as a measure and proxy for that team's ultimate success. In contrast, this project focuses on exploring new model design hypotheses, trained with an enhanced data set that consists of in-game match events, to effectively reflect the complex, multivariate nature of football. Furthermore, we constructively assess our models’ performance using customised evaluation metrics and compare them to that of the bookmakers’ models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from math import ceil\n",
    "from IPython.core.display import HTML\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "#Standard Python libraries for data and visualisation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly as ply\n",
    "\n",
    "#Import models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Import error metric\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Import data munging tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Display charts in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shots xG model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shot-based-data for predicting expected goals (xG) model, data was obtained from https://fbref.com. The data obtained consists of shots made in the match and match highlights at MAKO (minute after kick-off). \n",
    "Shot data was limited to the last 4 seasons, i.e., <b>2017-2021</b>.\n",
    "The data was scraped off the webpage with a custom built scraper.\n",
    "The scraper is available at ... insert here\n",
    "\n",
    "Currently our data contains the following values:\n",
    "    <li><b>Minute</b>: mins after kick-off shot took place, mis after the first half have 100 added to them.</li> \n",
    "    <li><b>Player</b>: player making the shot</li>\n",
    "    <li><b>Squad</b>: squad the player is from</li>\n",
    "    <li><b>Against</b>: squad against which shot is made</li>\n",
    "    <li><b>Outcome</b>: whether a shot is a goal|blocked|saved|etc.</li>\n",
    "    <li><b>Distance</b>: distance from the goal-post the shot was made</li>\n",
    "    <li><b>Body Part</b>: body part used to make the shot</li>\n",
    "    <li><b>Notes</b>: what kind of shot it was e.g. header|volley|etc.</li>\n",
    "    <li><b>SCA 1 Player</b>: player inducing event leading to shot</li> \n",
    "    <li><b>SCA 1 Event</b>: event leading to shot</li>\n",
    "    <li><b>SCA 2 Player</b>: player inducing event leading to 'SCA 1 Event'</li>\n",
    "    <li><b>SCA 2 Event</b>: event leading to 'SCA 1 Event'</li>\n",
    "    <li><b>Timestamp</b>: time and date of the kick-off</li>\n",
    "    <li><b>Score</b>: score of the squad at the time of the shot being taken</li>\n",
    "    <li><b>Player Advantage</b>: whether the squad has more players than the other</li>\n",
    "    <li><b>Threat</b>: threat level of the player making the shot</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_data = pd.read_csv('data/fantasy-league/shot_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Score</th>\n",
       "      <th>Player Advantage</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Player</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Against</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Body Part</th>\n",
       "      <th>Notes</th>\n",
       "      <th>SCA 1 Player</th>\n",
       "      <th>SCA 1 Event</th>\n",
       "      <th>SCA 2 Player</th>\n",
       "      <th>SCA 2 Event</th>\n",
       "      <th>Threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-08-13 12:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147</td>\n",
       "      <td>Riyad Mahrez</td>\n",
       "      <td>Leicester City</td>\n",
       "      <td>Hull City</td>\n",
       "      <td>Goal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Penalty Kick</td>\n",
       "      <td>Goal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-08-13 17:30:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Sergio Agüero</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>Goal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Penalty Kick</td>\n",
       "      <td>—</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-15 20:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147</td>\n",
       "      <td>Eden Hazard</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>West Ham United</td>\n",
       "      <td>Goal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Penalty Kick</td>\n",
       "      <td>Yellow Card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>627.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-19 20:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152</td>\n",
       "      <td>Zlatan Ibrahimović</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Goal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Penalty Kick</td>\n",
       "      <td>Goal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>627.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-08-20 12:30:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>Sergio Agüero</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Stoke City</td>\n",
       "      <td>Goal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Penalty Kick</td>\n",
       "      <td>Yellow Card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp  Score  Player Advantage  Minute              Player  \\\n",
       "0  2016-08-13 12:30:00    0.0               0.0     147        Riyad Mahrez   \n",
       "1  2016-08-13 17:30:00    1.0               0.0       4       Sergio Agüero   \n",
       "2  2016-08-15 20:00:00    1.0               0.0     147         Eden Hazard   \n",
       "3  2016-08-19 20:00:00    2.0               0.0     152  Zlatan Ibrahimović   \n",
       "4  2016-08-20 12:30:00    1.0               0.0      27       Sergio Agüero   \n",
       "\n",
       "               Squad          Against Outcome  Distance Body Part  \\\n",
       "0     Leicester City        Hull City    Goal       NaN       NaN   \n",
       "1    Manchester City       Sunderland    Goal       NaN       NaN   \n",
       "2            Chelsea  West Ham United    Goal       NaN       NaN   \n",
       "3  Manchester United      Southampton    Goal       NaN       NaN   \n",
       "4    Manchester City       Stoke City    Goal       NaN       NaN   \n",
       "\n",
       "          Notes SCA 1 Player SCA 1 Event SCA 2 Player SCA 2 Event  Threat  \n",
       "0  Penalty Kick         Goal         NaN          NaN         NaN   720.0  \n",
       "1  Penalty Kick            —         NaN          NaN         NaN   720.0  \n",
       "2  Penalty Kick  Yellow Card         NaN          NaN         NaN   627.0  \n",
       "3  Penalty Kick         Goal         NaN          NaN         NaN   627.0  \n",
       "4  Penalty Kick  Yellow Card         NaN          NaN         NaN     NaN  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shot_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-shots xG model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data\n",
    "\n",
    "For the non-shot-based expected goals (xG) model, we have obtained a dataset from [football-data.co.uk] (https://www.football-data.co.uk/) consisting of football match information over the past 10+ years. We have reduced this dataset to data from the last 5 seasons (including the current one), i.e., __2016-2021__. This version contains 1684 samples, each of which consists of 12 features and 2 labels of the full time home team goals (FTHG) and the full time away team goals (FTAG). The features are:\n",
    "\n",
    "1. GameID = Unique ID for the match\n",
    "2. Date = Match Date (dd/mm/yy)\n",
    "3. HomeTeam = Home Team\n",
    "4. AwayTeam = Away Team\n",
    "5. Referee = Match Referee\n",
    "6. HC = Home Team Corners\n",
    "7. AC = Away Team Corners\n",
    "8. HF = Home Team Fouls Committed\n",
    "9. AF = Away Team Fouls Committed\n",
    "10. HY = Home Team Yellow Cards\n",
    "11. AY = Away Team Yellow Cards\n",
    "12. HR = Home Team Red Cards\n",
    "13. AR = Away Team Red Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join(os.getcwd(), \"data/non-shot-xG/non_shot_data.csv\")\n",
    "complete_data = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameID</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Referee</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13/08/2016</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>J Moss</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13/08/2016</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>C Pawson</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13/08/2016</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>M Atkinson</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13/08/2016</td>\n",
       "      <td>Hull</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>M Dean</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13/08/2016</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>R Madley</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GameID        Date        HomeTeam    AwayTeam     Referee  HC  AC  HF  AF  \\\n",
       "0       1  13/08/2016         Burnley     Swansea      J Moss   7   4  10  14   \n",
       "1       2  13/08/2016  Crystal Palace   West Brom    C Pawson   3   6  12  15   \n",
       "2       3  13/08/2016         Everton   Tottenham  M Atkinson   5   6  10  14   \n",
       "3       4  13/08/2016            Hull   Leicester      M Dean   5   3   8  17   \n",
       "4       5  13/08/2016        Man City  Sunderland    R Madley   9   6  11  14   \n",
       "\n",
       "   HY  AY  HR  AR  FTHG  FTAG FTR  \n",
       "0   3   2   0   0     0     1   A  \n",
       "1   2   2   0   0     0     1   A  \n",
       "2   0   0   0   0     1     1   D  \n",
       "3   2   2   0   0     2     1   H  \n",
       "4   1   2   0   0     2     1   H  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shots xG model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set 'Timestamp' to datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_data['Timestamp'] = pd.to_datetime(shot_data['Timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we assume that getting near to the end of the match, shots patterns change as attacks become more aggressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_data['End_close'] = (shot_data['Minute'] > 185).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "null values of notes are associated with normal shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_data['Notes'] = shot_data['Notes'].fillna('normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separate Shot data by type\n",
    " We assume that a shots of different types have different probabilities of being a goal from the same distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_data_by_type(type_name, df):\n",
    "    # collect notes including the substring type_name, e.g. 'volley'\n",
    "    types = [v for v in df['Notes'].unique() if type_name in v.lower()]\n",
    "    # extract shots of the type specified\n",
    "    type_df = df[[n in types for n in df['Notes']]]\n",
    "    # deduce outcome of shot i.e. Goal or not Goal\n",
    "    type_goals = type_df['Outcome'] == 'Goal'\n",
    "    # drop unneeded columns\n",
    "    type_df = type_df.drop(columns=['Squad', 'Against', 'Outcome', 'Player', \n",
    "                                    'Body Part', 'SCA 1 Player', 'SCA 1 Event', \n",
    "                                   'SCA 2 Player', 'SCA 2 Event'])\n",
    "    # one-hot encoding for subtyoes\n",
    "    type_df = pd.concat([type_df, pd.get_dummies(type_df['Notes'])], axis=1)\n",
    "    # add a new column with label\n",
    "    type_df['Goal'] = type_goals.astype(int)\n",
    "    \n",
    "    return type_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "types of shots excluding normal, which conatains everything but those below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['volley', 'header', 'free kick', 'overhead', 'back heel', 'penalty kick']\n",
    "# collect all DataFrames for each type\n",
    "type_dfs = dict()\n",
    "# sets to keep records of which types of shots have been collected\n",
    "all_types = set(shot_data['Notes'].unique())\n",
    "used = set()\n",
    "\n",
    "for t in types:\n",
    "    # using the function, separates the shots by type\n",
    "    type_dfs[t] = shot_data_by_type(t, shot_data)\n",
    "    # adds used types to the set 'used'\n",
    "    used = used.union(set([v for v in shot_data['Notes'].unique() if t in v.lower()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remaining to be added to 'normal' shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_of_shots = list(all_types.difference(used))\n",
    "new_names = []\n",
    "\n",
    "# add normal to each type left for use of shot_data_by_type function\n",
    "for i in range(len(rest_of_shots)):\n",
    "    current = rest_of_shots[i]\n",
    "    new_names.append(current + ' normal' if not 'normal' == current else current)\n",
    "    \n",
    "# change notes according to above changes in the dataframe\n",
    "for o, n in zip(rest_of_shots, new_names):\n",
    "    # 'normal' does not change\n",
    "    if o != n:\n",
    "        originals = shot_data['Notes'] == o\n",
    "        shot_data.loc[originals, 'Notes'] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dfs['normal'] = shot_data_by_type('normal', shot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-shots xG model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take a look at different features — sanitise and standardise them for use in other models.\n",
    "\n",
    "__Note__: Standard team names and referee names along with their respective unique IDs are located in [this](data/standard) directory\n",
    "\n",
    "#### 1. Dropping columns that are not essential to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_training_data = complete_data.drop(['GameID','Date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Encode names of the teams and referees using standardised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_data = pd.read_csv(os.path.join(os.getcwd(), \"data/standard/standard.teamnames.csv\"))\n",
    "referee_data = pd.read_csv(os.path.join(os.getcwd(), \"data/standard/standard.referee.names.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating teams mappings \n",
    "teamname, teamID = list(teams_data['Standard teamname']), list(teams_data['TeamID'])\n",
    "teamID_mapping = dict(zip(teamname, teamID))\n",
    "\n",
    "generate_teamID_mappings = lambda teamnames: [teamID_mapping[teamname] for teamname in teamnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating referees mappings \n",
    "referee, refereeID = list(referee_data['Standard referee name']), list(referee_data['RefereeID'])\n",
    "refereeID_mapping = dict(zip(referee, refereeID))\n",
    "\n",
    "generate_refereeID_mappings = lambda referees: [refereeID_mapping[referee] for referee in referees]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying transformations to the (general) training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teams\n",
    "general_training_data['HomeTeam'] = generate_teamID_mappings(general_training_data['HomeTeam'])\n",
    "general_training_data['AwayTeam'] = generate_teamID_mappings(general_training_data['AwayTeam'])\n",
    "\n",
    "# Referees\n",
    "general_training_data['Referee'] = generate_refereeID_mappings(general_training_data['Referee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Integrating expected goals (xG) data from shots-based model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the results of the shots-based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots_xg_predictions = pd.read_csv(os.path.join(os.getcwd(), 'output/shots_xG_predictions.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add expected goals for the home team\n",
    "general_training_data['xHG'] = shots_xg_predictions['xG_h']\n",
    "\n",
    "# Add expected goals for the away team\n",
    "general_training_data['xAG'] = shots_xg_predictions['xG_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Referee</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>xHG</th>\n",
       "      <th>xAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0.955742</td>\n",
       "      <td>0.995993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1.955742</td>\n",
       "      <td>0.999136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>0.995993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>0.994346</td>\n",
       "      <td>0.996148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.995993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0.955742</td>\n",
       "      <td>1.995993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>0.955742</td>\n",
       "      <td>2.995993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.955742</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1684 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomeTeam  AwayTeam  Referee  HC  AC  HF  AF  HY  AY  HR  AR  FTHG  FTAG  \\\n",
       "0           10        34       12   7   4  10  14   3   2   0   0     0     1   \n",
       "1           13        37        7   3   6  12  15   2   2   0   0     0     1   \n",
       "2           14        35       18   5   6  10  14   0   0   0   0     1     1   \n",
       "3           18        20       20   5   3   8  17   2   2   0   0     2     1   \n",
       "4           22        33       34   9   6  11  14   1   2   0   0     2     1   \n",
       "...        ...       ...      ...  ..  ..  ..  ..  ..  ..  ..  ..   ...   ...   \n",
       "1679         9        40        1   5   8  13   8   2   1   0   0     3     3   \n",
       "1680        37         1       18   3   5   7   4   1   2   0   0     0     4   \n",
       "1681        25        20       33   3   6  10  11   0   2   0   0     1     2   \n",
       "1682        12        22        3   5   3  11  10   3   1   0   0     1     3   \n",
       "1683        31        21        2   1  10   5  12   1   3   0   0     1     0   \n",
       "\n",
       "     FTR       xHG       xAG  \n",
       "0      A  0.000000  0.995993  \n",
       "1      A  0.000000  0.995993  \n",
       "2      D  0.955742  0.995993  \n",
       "3      H  1.955742  0.999136  \n",
       "4      H  0.999340  0.995993  \n",
       "...   ..       ...       ...  \n",
       "1679   D  0.994346  0.996148  \n",
       "1680   A  0.000000  3.995993  \n",
       "1681   A  0.955742  1.995993  \n",
       "1682   A  0.955742  2.995993  \n",
       "1683   H  0.955742  0.000000  \n",
       "\n",
       "[1684 rows x 16 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of the non-shot-based model, we will split the dataset into two: one containing data for predicting the __FTHG__ (Full Time Home Goals) and one containing data for predicting the __FTAG__ (Full Time Away Goals).\n",
    "\n",
    "#### 4. Split the dataset into two parts: ``home_training_data`` and ``away_training_data``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_home = home_training_data = general_training_data.drop(['FTAG', 'FTHG', 'AC', 'xAG', 'FTR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Referee</th>\n",
       "      <th>HC</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>xHG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.955742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeTeam  AwayTeam  Referee  HC  HF  AF  HY  AY  HR  AR       xHG\n",
       "0        10        34       12   7  10  14   3   2   0   0  0.000000\n",
       "1        13        37        7   3  12  15   2   2   0   0  0.000000\n",
       "2        14        35       18   5  10  14   0   0   0   0  0.955742\n",
       "3        18        20       20   5   8  17   2   2   0   0  1.955742\n",
       "4        22        33       34   9  11  14   1   2   0   0  0.999340"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_home.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_away = home_training_data = general_training_data.drop(['FTHG', 'FTAG', 'HC', 'xHG', 'FTR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Referee</th>\n",
       "      <th>AC</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>xAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeTeam  AwayTeam  Referee  AC  HF  AF  HY  AY  HR  AR       xAG\n",
       "0        10        34       12   4  10  14   3   2   0   0  0.995993\n",
       "1        13        37        7   6  12  15   2   2   0   0  0.995993\n",
       "2        14        35       18   6  10  14   0   0   0   0  0.995993\n",
       "3        18        20       20   3   8  17   2   2   0   0  0.999136\n",
       "4        22        33       34   6  11  14   1   2   0   0  0.995993"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_away.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and validation\n",
    "\n",
    "### Shots xG model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_split_analysis(data):\n",
    "    # drop non-feature columns\n",
    "    data = data.drop(columns=['Timestamp', 'Notes', 'Minute'])\n",
    "    # fill null values in threat with mean\n",
    "    data['Threat'] = data['Threat'].fillna(data['Threat'].mean())\n",
    "    # separate label columns from data\n",
    "    goals = data['Goal']\n",
    "    data = data.drop(columns=['Goal'])\n",
    "    # fill any null value, only true for penalty kicks' distance\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    data[['Distance', 'Threat']] = scaler.fit_transform(data[['Distance', 'Threat']])\n",
    "    \n",
    "    return train_test_split(data, goals, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over each selected classifier and collect scores for each shot type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [GradientBoostingClassifier(max_depth=5, learning_rate=0.1, subsample=0.15),\n",
    "              GaussianNB(), LogisticRegression(max_iter=1000)]\n",
    "\n",
    "cls_names = ['xgbc',\n",
    "            'gaussian',\n",
    "            'log']\n",
    "\n",
    "cls_scores = []\n",
    "\n",
    "for cls in classifiers:\n",
    "    # variables to collect data\n",
    "    correct_shots = 0\n",
    "    goals = 0\n",
    "    false_goals = 0\n",
    "    f1_scores = 0\n",
    "    total_pred_goals = 0\n",
    "    total_shots = 0\n",
    "    total_goals = 0\n",
    "\n",
    "    # training and collecting result from each classifier over each type of shot\n",
    "    for k, v in type_dfs.items():\n",
    "\n",
    "        x_train, x_test, y_train, y_test = clean_split_analysis(v)\n",
    "        cls = cls.fit(x_train, y_train)\n",
    "        pred = cls.predict(x_test)\n",
    "\n",
    "        total_shots += len(y_test)\n",
    "        total_goals += sum(y_test > 0)\n",
    "        total_pred_goals += sum(pred > 0)\n",
    "\n",
    "        false_goals += sum(pred[pred > 0] != y_test[pred > 0])\n",
    "        correct_shots += sum(pred == y_test)\n",
    "        goals += sum(pred[y_test > 0] == y_test[y_test > 0])\n",
    "        f1_scores += f1_score(y_test, pred) * len(y_test)\n",
    "\n",
    "    cls_scores.append([correct_shots / total_shots, goals / total_goals, \n",
    "                   false_goals / total_pred_goals, f1_scores / total_shots])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put these readings into a DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new DataFrame object\n",
    "classifer_score_df = pd.DataFrame()\n",
    "# iterate over scores\n",
    "for n, s in zip(cls_names, cls_scores):\n",
    "    new_row = [n, *s]\n",
    "    classifer_score_df = classifer_score_df.append([new_row])\n",
    "    \n",
    "classifer_score_df.columns = ['Classifier', 'Accuracy', 'Recall', 'False Goals', 'F1 score']\n",
    "classifer_score_df = classifer_score_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Image generation requires the psutil package.\n\nInstall using pip:\n    $ pip install psutil\n\nInstall using conda:\n    $ conda install psutil\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-ac878a53151e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifer_score_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'False Goals'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F1 score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Classifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbarmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'group'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Classifier comparison'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_compare_shot_data.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m display(HTML('''<ol>\n",
      "\u001b[0;32m~/opt/anaconda3/envs/comp0036/lib/python3.7/site-packages/plotly/io/_kaleido.py\u001b[0m in \u001b[0;36mwrite_image\u001b[0;34m(fig, file, format, scale, width, height, validate, engine)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/comp0036/lib/python3.7/site-packages/plotly/io/_kaleido.py\u001b[0m in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate, engine)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"kaleido\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/comp0036/lib/python3.7/site-packages/plotly/io/_orca.py\u001b[0m in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate)\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;31m# Make sure orca sever is running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;31m# -------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m     \u001b[0mensure_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m     \u001b[0;31m# Handle defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/comp0036/lib/python3.7/site-packages/plotly/io/_orca.py\u001b[0m in \u001b[0;36mensure_server\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0mInstall\u001b[0m \u001b[0musing\u001b[0m \u001b[0mconda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;31m$\u001b[0m \u001b[0mconda\u001b[0m \u001b[0minstall\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m \"\"\"\n\u001b[0m\u001b[1;32m   1371\u001b[0m         )\n\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Image generation requires the psutil package.\n\nInstall using pip:\n    $ pip install psutil\n\nInstall using conda:\n    $ conda install psutil\n"
     ]
    }
   ],
   "source": [
    "fig = px.bar(classifer_score_df, y=['Accuracy', 'Recall', 'False Goals', 'F1 score'], x='Classifier', barmode='group', title='Classifier comparison')\n",
    "ply.io.write_image(fig, 'model_compare_shot_data.jpeg')\n",
    "fig.show()\n",
    "\n",
    "display(HTML('''<ol>\n",
    "            <li><strong>Accuracy</strong>: correctly predicted shots / total shots</li>\n",
    "            <li><strong>Recall</strong>: correctly classified goals / actual goals</li>\n",
    "            <li><strong>False positives</strong>: incorrectly classified goals / actual goals</li>\n",
    "            <li><strong>F1 score</strong>: F1 score of the classifier</li>\n",
    "        </ol><br>\n",
    "        Accuracy is not a reliable metric in this case due to uneven label numbers.<br>\n",
    "        We instead rely on F1 scores while keeping an eye on True positives and False positives.<br>\n",
    "        F1 scores for all three models are similar, we focus on True positives as a secondary metric since \n",
    "        our aim is to correctly predict goals.\n",
    "        <br><br>\n",
    "        <strong>From the data we can conclude that the Logistic Regression is the best option for \n",
    "        this classification.</strong>'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_split_validation(data):\n",
    "    # drop non-feature columns\n",
    "    data = data.drop(columns=['Timestamp', 'Notes', 'Minute'])\n",
    "    # fill null values in threat with mean\n",
    "    data['Threat'] = data['Threat'].fillna(data['Threat'].mean())\n",
    "    # separate label columns from data\n",
    "    goals = data['Goal']\n",
    "    data = data.drop(columns=['Goal'])\n",
    "    # fill any null value, only true for penalty kicks' distance\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    data[['Distance', 'Threat']] = scaler.fit_transform(data[['Distance', 'Threat']])\n",
    "    \n",
    "    return train_test_split(data, goals, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over each selected classifier and collect scores for each shot type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [GradientBoostingClassifier(max_depth=2, learning_rate=0.1, subsample=0.15),\n",
    "               GradientBoostingClassifier(max_depth=3, learning_rate=0.1, subsample=0.15),\n",
    "              GradientBoostingClassifier(max_depth=4, learning_rate=0.1, subsample=0.15),\n",
    "              GradientBoostingClassifier(max_depth=5, learning_rate=0.1, subsample=0.15),\n",
    "              GradientBoostingClassifier(max_depth=7, learning_rate=0.1, subsample=0.15),\n",
    "              GradientBoostingClassifier(max_depth=10, learning_rate=0.1, subsample=0.15)]\n",
    "\n",
    "cls_scores = []\n",
    "\n",
    "cls_names = ['2', '3', '4', '5', '7', '10']\n",
    "\n",
    "for cls in classifiers:\n",
    "    # variables to collect data\n",
    "    correct_shots = 0\n",
    "    goals = 0\n",
    "    false_goals = 0\n",
    "    f1_scores = 0\n",
    "    total_pred_goals = 0\n",
    "    total_shots = 0\n",
    "    total_goals = 0\n",
    "\n",
    "    # training and collecting result from each classifier over each type of shot\n",
    "    for k, v in type_dfs.items():\n",
    "\n",
    "        x_train, x_test, y_train, y_test = clean_split_validation(v)\n",
    "        cls = cls.fit(x_train, y_train)\n",
    "        pred = cls.predict(x_test)\n",
    "\n",
    "        total_shots += len(y_test)\n",
    "        total_goals += sum(y_test > 0)\n",
    "        total_pred_goals += sum(pred > 0)\n",
    "\n",
    "        false_goals += sum(pred[pred > 0] != y_test[pred > 0])\n",
    "        correct_shots += sum(pred == y_test)\n",
    "        goals += sum(pred[y_test > 0] == y_test[y_test > 0])\n",
    "        f1_scores += f1_score(y_test, pred) * len(y_test)\n",
    "\n",
    "    cls_scores.append([correct_shots / total_shots, goals / total_goals, \n",
    "                   false_goals / total_pred_goals, f1_scores / total_shots])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put these readings into a DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new DataFrame object\n",
    "classifer_score_df = pd.DataFrame()\n",
    "# iterate over scores\n",
    "for n, s in zip(cls_names, cls_scores):\n",
    "    new_row = [n, *s]\n",
    "    classifer_score_df = classifer_score_df.append([new_row])\n",
    "    \n",
    "classifer_score_df.columns = ['Classifier', 'Accuracy', 'Recall', 'False Goals', 'F1 score']\n",
    "classifer_score_df = classifer_score_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Image generation requires the psutil package.\n\nInstall using pip:\n    $ pip install psutil\n\nInstall using conda:\n    $ conda install psutil\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-92d63504a5c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifer_score_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'False Goals'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F1 score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Classifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbarmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'group'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Classifier comparison'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_valid_xgbc_shot_data.jpeg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m display(HTML('''<ol>\n",
      "\u001b[0;32m~/opt/anaconda3/envs/comp0036/lib/python3.7/site-packages/plotly/io/_kaleido.py\u001b[0m in \u001b[0;36mwrite_image\u001b[0;34m(fig, file, format, scale, width, height, validate, engine)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/comp0036/lib/python3.7/site-packages/plotly/io/_kaleido.py\u001b[0m in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate, engine)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"kaleido\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/comp0036/lib/python3.7/site-packages/plotly/io/_orca.py\u001b[0m in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate)\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;31m# Make sure orca sever is running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;31m# -------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m     \u001b[0mensure_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m     \u001b[0;31m# Handle defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/comp0036/lib/python3.7/site-packages/plotly/io/_orca.py\u001b[0m in \u001b[0;36mensure_server\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0mInstall\u001b[0m \u001b[0musing\u001b[0m \u001b[0mconda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;31m$\u001b[0m \u001b[0mconda\u001b[0m \u001b[0minstall\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m \"\"\"\n\u001b[0m\u001b[1;32m   1371\u001b[0m         )\n\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Image generation requires the psutil package.\n\nInstall using pip:\n    $ pip install psutil\n\nInstall using conda:\n    $ conda install psutil\n"
     ]
    }
   ],
   "source": [
    "fig = px.bar(classifer_score_df, y=['Accuracy', 'Recall', 'False Goals', 'F1 score'], x='Classifier', barmode='group', title='Classifier comparison')\n",
    "ply.io.write_image(fig, \"model_valid_xgbc_shot_data.jpeg\")\n",
    "fig.show()\n",
    "\n",
    "display(HTML('''<ol>\n",
    "            <li><strong>Accuracy</strong>: correctly predicted shots / total shots</li>\n",
    "            <li><strong>Recall</strong>: correctly classified goals / actual goals</li>\n",
    "            <li><strong>False Goals</strong>: incorrectly classified goals / actual goals</li>\n",
    "            <li><strong>F1 score</strong>: F1 score of the classifier</li>\n",
    "        </ol><br>\n",
    "        Accuracy is not a reliable metric in this case due to uneven label numbers.<br>\n",
    "        We instead rely on F1 scores while keeping an eye on True positives and False positives.<br>\n",
    "        F1 scores for all three models are similar, we focus on True positives as a secondary metric since \n",
    "        our aim is to correctly predict goals.\n",
    "        <br><br>\n",
    "        <strong>From the data we can conclude that a a max depth of 4 is the best option.<br>\n",
    "        Since the Logistic Regression performs better than this hyperparam of XGBC, we use Logistic Regression\n",
    "        as our model</strong>'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_train_ready(data):\n",
    "    # drop columns which are not selected as features in our model\n",
    "    data = data.drop(columns=['Timestamp', 'Notes', 'Minute'])\n",
    "    # fill empty threat values with mean\n",
    "    data['Threat'] = data['Threat'].fillna(data['Threat'].mean())\n",
    "    # separate 'Goal' columns, they are considered labels\n",
    "    goals = data['Goal']\n",
    "    data = data.drop(columns=['Goal'])\n",
    "    \n",
    "    return train_test_split(data, goals, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    cls = LogisticRegression(max_iter=1000)\n",
    "    cls.fit(x_train, y_train)\n",
    "    \n",
    "    return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_by_type = {}\n",
    "\n",
    "for k, v in type_dfs.items():\n",
    "    \n",
    "    model_ready_data = get_data_train_ready(type_dfs[k].fillna(0))\n",
    "    \n",
    "    clsf = get_classifier(*model_ready_data)\n",
    "    \n",
    "    classifier_by_type[k] = clsf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load shot_data with match_ids\n",
    "path = os.path.join(os.getcwd(), \"output/shot_data.csv\")\n",
    "shot_data_m_ids = pd.read_csv(path)\n",
    "shot_data_m_ids['MatchID'] = shot_data_m_ids['MatchID'] - 3040\n",
    "shot_data_m_ids['Timestamp'] = pd.to_datetime(shot_data_m_ids['Timestamp'])\n",
    "shot_data_m_ids['End_close'] = (shot_data_m_ids['Minute'] > 185).astype(int)\n",
    "shot_data_m_ids['Notes'] = shot_data_m_ids['Notes'].fillna('normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separate Shot data by type\n",
    " We assume that a shots of different types have different probabilities of being a goal from the same distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_data_by_type(type_name, df):\n",
    "    # collect notes including the substring type_name, e.g. 'volley'\n",
    "    types = [v for v in df['Notes'].unique() if type_name in v.lower()]\n",
    "    # extract shots of the type specified\n",
    "    type_df = df[[n in types for n in df['Notes']]]\n",
    "    # deduce outcome of shot i.e. Goal or not Goal\n",
    "    type_goals = type_df['Outcome'] == 'Goal'\n",
    "    # drop unneeded columns\n",
    "    type_df = type_df.drop(columns=['Against', 'Outcome', 'Player', \n",
    "                                    'Body Part', 'SCA 1 Player', 'SCA 1 Event', \n",
    "                                   'SCA 2 Player', 'SCA 2 Event'])\n",
    "    # one-hot encoding for subtyoes\n",
    "    type_df = pd.concat([type_df, pd.get_dummies(type_df['Notes'])], axis=1)\n",
    "    # add a new column with label\n",
    "    type_df['Goal'] = type_goals.astype(int)\n",
    "    \n",
    "    return type_df\n",
    "\n",
    "def shot_data_by_type(type_name, df):\n",
    "    # collect notes including the substring type_name, e.g. 'volley'\n",
    "    types = [v for v in df['Notes'].unique() if type_name in v.lower()]\n",
    "    # extract shots of the type specified\n",
    "    type_df = df[[n in types for n in df['Notes']]]\n",
    "    type_df = type_df.reset_index(drop=True)\n",
    "     # deduce outcome of shot i.e. Goal or not Goal\n",
    "    type_goals = type_df['Outcome'] == 'Goal'\n",
    "    # drop unneeded columns\n",
    "    type_df = type_df.drop(columns=['Against', 'Outcome', 'Player', \n",
    "                                    'Body Part', 'SCA 1 Player', 'SCA 1 Event', \n",
    "                                   'SCA 2 Player', 'SCA 2 Event'])\n",
    "    # one-hot encoding for subtyoes\n",
    "    type_df = pd.concat([type_df, pd.get_dummies(type_df['Notes'])], axis=1)\n",
    "    # add a new column with label\n",
    "    type_df['Goal'] = type_goals.astype(int)\n",
    "    \n",
    "    return type_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "types of shots excluding normal, which conatains everything but those below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['volley', 'header', 'free kick', 'overhead', 'back heel', 'penalty kick']\n",
    "# collect all DataFrames for each type\n",
    "type_dfs = dict()\n",
    "# sets to keep records of which types of shots have been collected\n",
    "all_types = set(shot_data_m_ids['Notes'].unique())\n",
    "used = set()\n",
    "\n",
    "for t in types:\n",
    "    # using the function, separates the shots by type\n",
    "    type_dfs[t] = shot_data_by_type(t, shot_data_m_ids)\n",
    "    # adds used types to the set 'used'\n",
    "    used = used.union(set([v for v in shot_data['Notes'].unique() if t in v.lower()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remaining to be added to 'normal' shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deflected', 'Lob', 'Open goal', 'normal'}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_types.difference(used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_of_shots = list(all_types.difference(used))\n",
    "new_names = list(range(len(rest_of_shots)))\n",
    "\n",
    "# add normal to each type left for use of shot_data_by_type function\n",
    "for i in range(len(rest_of_shots)):\n",
    "    current = rest_of_shots[i]\n",
    "    new_names[i] = current + ' normal' if not 'normal' == current else current\n",
    "    \n",
    "# change notes according to above changes in the dataframe\n",
    "for o, n in zip(rest_of_shots, new_names):\n",
    "    # 'normal' does not change\n",
    "    if o != n:\n",
    "        originals = shot_data_m_ids['Notes'] == o\n",
    "        shot_data_m_ids.loc[originals, 'Notes'] = n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dfs['normal'] = shot_data_by_type('normal', shot_data_m_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We sum over the probabilities of each team in a match to the expected goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_expected_goals(key, type_dfs, cls_s, collecting_df):\n",
    "    '''Calculates the expected goals in a match by a team based on shots made and classifiers trained.'''\n",
    "    data = type_dfs[key]\n",
    "    # fill empty threat values\n",
    "    data['Threat'] = data['Threat'].fillna(data['Threat'].mean())\n",
    "    # group the data by 'MatchID'\n",
    "    ids = data.groupby('MatchID').groups\n",
    "    # get classifier for type of shot\n",
    "    cls = cls_s[key]\n",
    "    \n",
    "    for k, v in ids.items():\n",
    "        # get shots for the match\n",
    "        match_data = data.iloc[v]\n",
    "        # split data over Squads\n",
    "        teams = match_data.groupby('Squad').groups\n",
    "        \n",
    "        for t, d in teams.items():\n",
    "            # team shot data\n",
    "            team_data = data.loc[d]\n",
    "            # drop Squad column\n",
    "            team_data = team_data.drop(columns=['Squad', 'Goal',\n",
    "                                                'Timestamp', 'Notes', \n",
    "                                                'Minute', 'MatchID'])\n",
    "            # fill empty values with 0\n",
    "            team_data = team_data.fillna(0)\n",
    "            prob = cls.predict_proba(team_data)\n",
    "            # sum over probabilites of all shots\n",
    "            collecting_df = collecting_df.append([[k, t, sum(prob[:, 1])]])\n",
    "    \n",
    "    return collecting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "collecting_df = pd.DataFrame()\n",
    "# collect all predicted goals for each team in each match\n",
    "for k in type_dfs.keys():\n",
    "    collecting_df = calc_expected_goals(k, type_dfs, classifier_by_type, collecting_df)\n",
    "# set column names\n",
    "collecting_df.columns = ['GameID', 'Squad', 'xG']\n",
    "# sort on 'GameID'\n",
    "collecting_df = collecting_df.sort_values('GameID').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameID</th>\n",
       "      <th>Squad</th>\n",
       "      <th>xG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>0.999136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Man City</td>\n",
       "      <td>0.999340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>0.998984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Man United</td>\n",
       "      <td>0.999224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>0.994077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GameID       Squad        xG\n",
       "0     4.0   Leicester  0.999136\n",
       "1     5.0    Man City  0.999340\n",
       "2    10.0     Chelsea  0.998984\n",
       "3    11.0  Man United  0.999224\n",
       "4    14.0       Stoke  0.994077"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    xG represents the probability of a shot being a goal.<br>\n",
       "    Next, we move onto adding all probabilities of shots in a match for a team to get\n",
       "    expected goals.\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(collecting_df.head())\n",
    "\n",
    "display(HTML('''\n",
    "    xG represents the probability of a shot being a goal.<br>\n",
    "    Next, we move onto adding all probabilities of shots in a match for a team to get\n",
    "    expected goals.\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We sum over the probabilities of each team in a match to the expected goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = collecting_df.groupby('GameID').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_gx = pd.DataFrame()\n",
    "\n",
    "for k, v in matches.items():\n",
    "    # get match rows\n",
    "    match = collecting_df.loc[v]\n",
    "    # get team names\n",
    "    teams = match['Squad'].unique()\n",
    "    # remove any null rows\n",
    "    teams = teams[~pd.isnull(teams)]\n",
    "    \n",
    "    team_list = []\n",
    "    # collect expected goals for each team\n",
    "    for team in teams:\n",
    "        team_rows_b = team == match['Squad']\n",
    "        team_rows = match[team_rows_b]\n",
    "        xG = sum(team_rows['xG'])\n",
    "        team_list.append([team, xG])\n",
    "    \n",
    "    if len(team_list) == 1:\n",
    "        match_gx = match_gx.append([[k, *team_list[0], np.NaN, np.NaN]])\n",
    "    else:\n",
    "        match_gx = match_gx.append([[k, *team_list[0], *team_list[1]]])\n",
    "    \n",
    "match_gx = match_gx.reset_index(drop=True)\n",
    "match_gx.columns = ['GameID', 'Squad_a', 'xG_a', 'Squad_b', 'xG_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameID</th>\n",
       "      <th>Squad_a</th>\n",
       "      <th>xG_a</th>\n",
       "      <th>Squad_b</th>\n",
       "      <th>xG_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Man City</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Man United</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>0.994077</td>\n",
       "      <td>Man City</td>\n",
       "      <td>0.994962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GameID     Squad_a      xG_a   Squad_b      xG_b\n",
       "0     4.0   Leicester  0.999136       NaN       NaN\n",
       "1     5.0    Man City  0.999340       NaN       NaN\n",
       "2    10.0     Chelsea  0.998984       NaN       NaN\n",
       "3    11.0  Man United  0.999224       NaN       NaN\n",
       "4    14.0       Stoke  0.994077  Man City  0.994962"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_gx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We now separate Squads with the same MatchID into Home and Away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_shot_data = pd.read_csv('data/non-shot-xG/non_shot_data.csv', index_col=0)\n",
    "non_shot_data['Date'] = pd.to_datetime(non_shot_data['Date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_data_xg = pd.DataFrame()\n",
    "\n",
    "for i, m in match_gx.iterrows():\n",
    "    game_id = int(m['GameID'])\n",
    "    # due to various versions of Data-sets, \n",
    "    # some indices might have changed or \n",
    "    # may not bethe same anymore\n",
    "    if not game_id in non_shot_data.index.tolist():\n",
    "        continue\n",
    "    # get match row from non_shot_data\n",
    "    match_row = non_shot_data.loc[game_id]\n",
    "    \n",
    "    # check if squad_a is HomeTeam\n",
    "    squad_a_home = m['Squad_a'] == match_row['HomeTeam']\n",
    "    if not squad_a_home:\n",
    "        # if squad_a is not the HomeTeam, it must be the AwayTeam\n",
    "        assert(m['Squad_a'] == match_row['AwayTeam'])\n",
    "    \n",
    "    # assign according to squad_a_home deduced above\n",
    "    if squad_a_home:\n",
    "        xG_home = m['xG_a']\n",
    "        xG_away = m['xG_b']\n",
    "    else:\n",
    "        xG_away = m['xG_a']\n",
    "        xG_home = m['xG_b']\n",
    "        \n",
    "    # add as a row to DataFrame \n",
    "    shot_data_xg = shot_data_xg.append([[game_id, xG_home, xG_away]])\n",
    "    \n",
    "# set columns and reset index\n",
    "shot_data_xg = shot_data_xg.reset_index(drop=True)\n",
    "shot_data_xg.columns = ['GameID', 'xG_h', 'xG_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_data_xg.index = shot_data_xg['GameID']\n",
    "shot_data_xg = shot_data_xg.drop(columns=['GameID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add xG_a, xG_h as columns to non_shot_data\n",
    "all_game_data = pd.concat([non_shot_data, shot_data_xg], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save CSV\n",
    "path = os.path.join(os.getcwd(), \"output/shots_xG_predictions.csv\")\n",
    "all_game_data.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill missing xG values\n",
    "We fill these by taking the average of the difference between xG_(a|h) and FT(A|H)G<br>\n",
    "The difference is then subtracted from FT(A|H)G to get an estimate of xG_(a|h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), \"output/shots_xG_predictions.csv\")\n",
    "all_game_data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_goals = all_game_data[['FTHG', 'xG_h']].dropna()\n",
    "\n",
    "away_goals = all_game_data[['FTAG', 'xG_a']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_goals['Difference'] = home_goals['FTHG'] - home_goals['xG_h']\n",
    "a = home_goals['Difference'] > home_goals['Difference'].quantile(0.1)\n",
    "b = home_goals['Difference'] < home_goals['Difference'].quantile(0.9)\n",
    "dif = home_goals[np.logical_and(a, b)]['Difference'].mean()\n",
    "\n",
    "missing = pd.isnull(all_game_data['xG_h'])\n",
    "\n",
    "all_game_data.loc[missing, 'xG_h'] = all_game_data.loc[missing, 'FTHG'] - dif\n",
    "\n",
    "below_zero = all_game_data.loc[missing, 'xG_h'] < 0\n",
    "\n",
    "all_game_data.loc[below_zero & missing, 'xG_h'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_goals['Difference'] = away_goals['FTAG'] - away_goals['xG_a']\n",
    "a = away_goals['Difference'] > away_goals['Difference'].quantile(0.1)\n",
    "b = away_goals['Difference'] < away_goals['Difference'].quantile(0.9)\n",
    "dif = away_goals[np.logical_and(a, b)]['Difference'].mean()\n",
    "\n",
    "missing = pd.isnull(all_game_data['xG_a'])\n",
    "\n",
    "all_game_data.loc[missing, 'xG_a'] = all_game_data.loc[missing, 'FTAG'] - dif\n",
    "\n",
    "below_zero = all_game_data.loc[missing, 'xG_a'] < 0\n",
    "\n",
    "all_game_data.loc[below_zero & missing, 'xG_a'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we check if any values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(all_game_data[['xG_h', 'xG_a']]).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_with_xG = all_game_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), \"output/shots_xG_predictions.csv\")\n",
    "complete_data_with_xG.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-shots xG model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train both (__FTHG__ and __FTAG__) models, we will use the [Random Forest Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) along with grid search with cross-validation to estimate hyperparameters. An analysis on why this specific learning method was used is presented in the report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FTHG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_home = general_training_data.FTHG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will determine the optimal values to be used for the hyperparameters of our model from a specified range of values. We have chosen the two hyperparameters; ``max_depth`` and ``n_estimators`` to be optimised. ``max_depth`` refers to the maximum depth of the decision trees and ``n_estimators`` refers to the number of trees in the forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform grid search to obtain optimal parameter values\n",
    "gsc = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(),\n",
    "        param_grid={\n",
    "            'max_depth': range(3,7),\n",
    "            'n_estimators': (10, 50, 100, 500, 1000),\n",
    "        },\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "\n",
    "grid_result = gsc.fit(X_home, Y_home)\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "display(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best_params to the model\n",
    "model_home = RandomForestRegressor(\n",
    "    max_depth=best_params[\"max_depth\"], n_estimators=best_params[\"n_estimators\"], random_state=False, verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After estimating hyperparameters for the model, we randomly split the data into training and testing sets to get a representation of all data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_home_train, X_home_test, Y_home_train, Y_home_test = train_test_split(X_home, Y_home, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=5, n_estimators=500, random_state=False,\n",
       "                      verbose=False)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_home.fit(X_home_train, Y_home_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now apply the trained model to make predictions on the test set (X_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_home_pred_test = model_home.predict(X_home_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has now been trained to learn the relationships between the features and the targets. To evaluate the performance of the model, we use both train-test split and K-Fold cross validation. The error metric values chosen here are the __Mean Absolute Error (MAE)__, __Mean Squared Error (MASE)__, and the __Coefficient of Determination (R2 Score)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test split result:\n",
      "\n",
      "Mean squared error (MSE): 0.577235\n",
      "Mean absolute error (MAE): 0.464697\n",
      "Coefficient of determination (R^2): 0.645010\n"
     ]
    }
   ],
   "source": [
    "print('Train-test split result:\\n')\n",
    "\n",
    "print('Mean squared error (MSE): %f'\n",
    "      % mean_squared_error(Y_home_test, Y_home_pred_test))\n",
    "print('Mean absolute error (MAE): %f'\n",
    "      % mean_absolute_error(Y_home_test, Y_home_pred_test))\n",
    "print('Coefficient of determination (R^2): %f'\n",
    "      % r2_score(Y_home_test, Y_home_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pass the model to the `cross_val_score()` function which performs K-Fold cross validation on the given data and provides as an output, an error metric value, which can be used to determine the model performance. The error metric values chosen here are the same: __Mean Squared Error (MSE)__, __Mean Absolute Error (MAE)__, and the __Coefficient of Determination (R2 Score)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross validation result:\n",
      "\n",
      "Mean squared error (MSE): 0.6138261764042214\n",
      "Mean absolute error (MAE): 0.46714036725721025\n",
      "Coefficient of determination (R2 Score): 0.6391747979551518\n"
     ]
    }
   ],
   "source": [
    "model_home_mse_scores = cross_val_score(model_home, X_home, Y_home, cv=5, scoring='neg_mean_squared_error')\n",
    "model_home_mae_scores = cross_val_score(model_home, X_home, Y_home, cv=5, scoring='neg_mean_absolute_error') \n",
    "model_home_r2_scores = cross_val_score(model_home, X_home, Y_home, cv=5, scoring='r2')\n",
    "\n",
    "print('K-fold cross validation result:\\n')\n",
    "\n",
    "print('Mean squared error (MSE): {n}'.format(n=abs(np.mean(model_home_mse_scores))))\n",
    "print('Mean absolute error (MAE): {n}'.format(n=abs(np.mean(model_home_mae_scores))))\n",
    "print('Coefficient of determination (R2 Score): {n}'.format(n=abs(np.mean(model_home_r2_scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now repeating the process for the FTAG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_away = general_training_data.FTAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'n_estimators': 1000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform grid search to obtain optimal parameter values\n",
    "gsc = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(),\n",
    "        param_grid={\n",
    "            'max_depth': range(3,7),\n",
    "            'n_estimators': (10, 50, 100, 500, 1000),\n",
    "        },\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "\n",
    "grid_result = gsc.fit(X_away, Y_away)\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "display(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_away = RandomForestRegressor(\n",
    "    max_depth=best_params[\"max_depth\"], n_estimators=best_params[\"n_estimators\"], random_state=False, verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_away_train, X_away_test, Y_away_train, Y_away_test = train_test_split(X_away, Y_away, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=4, n_estimators=1000, random_state=False,\n",
       "                      verbose=False)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_away.fit(X_away_train, Y_away_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_away_pred_test = model_away.predict(X_away_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test split result:\n",
      "\n",
      "Mean squared error (MSE): 0.461291\n",
      "Mean absolute error (MAE): 0.445057\n",
      "Coefficient of determination (R^2): 0.649843\n"
     ]
    }
   ],
   "source": [
    "print('Train-test split result:\\n')\n",
    "\n",
    "print('Mean squared error (MSE): %f'\n",
    "      % mean_squared_error(Y_away_test, Y_away_pred_test))\n",
    "print('Mean absolute error (MAE): %f'\n",
    "      % mean_absolute_error(Y_away_test, Y_away_pred_test))\n",
    "print('Coefficient of determination (R^2): %f'\n",
    "      % r2_score(Y_away_test, Y_away_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross validation result:\n",
      "\n",
      "Mean squared error (MSE): 0.5456203163693599\n",
      "Mean absolute error (MAE): 0.4427483296393975\n",
      "Coefficient of determination (R2 Score): 0.6252336122742194\n"
     ]
    }
   ],
   "source": [
    "model_away_mse_scores = cross_val_score(model_away, X_away, Y_away, cv=5, scoring='neg_mean_squared_error')\n",
    "model_away_mae_scores = cross_val_score(model_away, X_away, Y_away, cv=5, scoring='neg_mean_absolute_error') \n",
    "model_away_r2_scores = cross_val_score(model_away, X_away, Y_away, cv=5, scoring='r2')\n",
    "\n",
    "print('K-fold cross validation result:\\n')\n",
    "\n",
    "print('Mean squared error (MSE): {n}'.format(n=abs(np.mean(model_away_mse_scores))))\n",
    "print('Mean absolute error (MAE): {n}'.format(n=abs(np.mean(model_away_mae_scores))))\n",
    "print('Coefficient of determination (R2 Score): {n}'.format(n=abs(np.mean(model_away_r2_scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FTHG Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_training_data = general_training_data.copy().drop(['FTAG', 'AC', 'xAG', 'FTR'], axis=1)\n",
    "home_model_input_data = home_training_data.copy().drop(columns=['FTHG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Referee</th>\n",
       "      <th>HC</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>xHG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.955742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeTeam  AwayTeam  Referee  HC  HF  AF  HY  AY  HR  AR  FTHG       xHG\n",
       "0        10        34       12   7  10  14   3   2   0   0     0  0.000000\n",
       "1        13        37        7   3  12  15   2   2   0   0     0  0.000000\n",
       "2        14        35       18   5  10  14   0   0   0   0     1  0.955742\n",
       "3        18        20       20   5   8  17   2   2   0   0     2  1.955742\n",
       "4        22        33       34   9  11  14   1   2   0   0     2  0.999340"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_pred_data = pd.get_dummies(home_model_input_data)\n",
    "home_r = model_home.predict(home_pred_data)\n",
    "home_r = pd.DataFrame(home_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_r.columns= ['Predicted FTHG']\n",
    "home_training_data.reset_index(drop=True, inplace=True)\n",
    "home_results = pd.concat([home_training_data, home_r], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FTAG Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_training_data = general_training_data.copy().drop(['FTHG', 'HC', 'xHG', 'FTR'], axis=1)\n",
    "away_model_input_data = away_training_data.copy().drop(columns=['FTAG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_pred_data = pd.get_dummies(away_model_input_data)\n",
    "away_r = model_away.predict(away_pred_data)\n",
    "away_r = pd.DataFrame(away_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_r.columns= ['Predicted FTAG']\n",
    "away_training_data.reset_index(drop=True, inplace=True)\n",
    "away_results = pd.concat([away_training_data, away_r], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging results of both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>Referee</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>xHG</th>\n",
       "      <th>xAG</th>\n",
       "      <th>Predicted FTHG</th>\n",
       "      <th>Predicted FTAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.119157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.096418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0.955742</td>\n",
       "      <td>0.995993</td>\n",
       "      <td>0.989988</td>\n",
       "      <td>1.094541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1.955742</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>2.031948</td>\n",
       "      <td>1.196834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>0.995993</td>\n",
       "      <td>2.254710</td>\n",
       "      <td>1.100860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeTeam  AwayTeam  Referee  HC  AC  HF  AF  HY  AY  HR  AR  FTHG  FTAG  \\\n",
       "0        10        34       12   7   4  10  14   3   2   0   0     0     1   \n",
       "1        13        37        7   3   6  12  15   2   2   0   0     0     1   \n",
       "2        14        35       18   5   6  10  14   0   0   0   0     1     1   \n",
       "3        18        20       20   5   3   8  17   2   2   0   0     2     1   \n",
       "4        22        33       34   9   6  11  14   1   2   0   0     2     1   \n",
       "\n",
       "  FTR       xHG       xAG  Predicted FTHG  Predicted FTAG  \n",
       "0   A  0.000000  0.995993        0.000000        1.119157  \n",
       "1   A  0.000000  0.995993        0.000000        1.096418  \n",
       "2   D  0.955742  0.995993        0.989988        1.094541  \n",
       "3   H  1.955742  0.999136        2.031948        1.196834  \n",
       "4   H  0.999340  0.995993        2.254710        1.100860  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_non_shot_predictions = general_training_data.copy()\n",
    "\n",
    "# Add predicted FTHG\n",
    "complete_non_shot_predictions['Predicted FTHG'] = home_results['Predicted FTHG']\n",
    "\n",
    "# Add predicted FTAG\n",
    "complete_non_shot_predictions['Predicted FTAG'] = away_results['Predicted FTAG']\n",
    "\n",
    "complete_non_shot_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), \"output/non_shot_predictions.csv\")\n",
    "complete_non_shot_predictions.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELO Rating classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offensive and defensive ELO ratings to predict number of goals\n",
    "\n",
    "We keep track of two ratings for all teams offensive rating ($R_O$) and defensive rating ($R_D$).\n",
    "\n",
    "We can then predict the number of goals a team will score by taking the difference of their offensive rating and the opponent's defensive rating.\n",
    "\n",
    "The number of goals scored against them can be calculated by considering it from the opponent's perspective.\n",
    "\n",
    "$E[\\text{team}] = R_O[\\text{team}] - R_D[\\text{opponent}]$\n",
    "\n",
    "We can update a team's offensive rating by adding the difference between the actual number of goals and the expected goals multiplied by the learning rate.\n",
    "We can update a team's defensive rating by adding the difference between the expected goals scored against them and the actual number of goals scored against them multiplied by the learning rate.\n",
    "\n",
    "$R_O[\\text{team}] = R_O[\\text{team}] + k(G[\\text{team}] - E[\\text{team}])$\n",
    "\n",
    "$R_D[\\text{team}] = R_D[\\text{team}] + k(E[\\text{opponent}] - G[\\text{opponent}])$\n",
    "\n",
    "We start every team with a rating of 0. The order of the training data makes a difference to the model and so the training data should be in chronological order in order to account for teams changing over team.\n",
    "\n",
    "We take the output of the elo rating predictor and use it to predict the final result. This is done using a simple piecewise function with an optimised draw size and a SVC. The results are compared and the SVC is chosen because it is more accurate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalElo:\n",
    "    def __init__(self, initial_rating=0, learning_rate=0.05, draw_size=0.5):\n",
    "        self.offensive_ratings = defaultdict(lambda: initial_rating)\n",
    "        self.defensive_ratings = defaultdict(lambda: initial_rating)\n",
    "        self.match_count = defaultdict(lambda: 0)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.draw_size = draw_size\n",
    "\n",
    "    def predict(self, team, opponent):\n",
    "        ''' Predicts the number of goals team will score against opponent. '''\n",
    "        return self.offensive_ratings[team] - self.defensive_ratings[opponent]\n",
    "\n",
    "    def predict_result(self, team, opponent):\n",
    "        ''' Predicts the result of a match. 1 if team wins, 0 if opponent wins and 0.5 if it is a draw. '''\n",
    "        goals_scored = self.predict(team, opponent)\n",
    "        goals_conceded = self.predict(opponent, team)\n",
    "        return self.classify_result(goals_scored, goals_conceded)\n",
    "\n",
    "    def classify_result(self, goals_scored, goals_conceded):\n",
    "        ''' Piecewise function to predict result from number of goals '''\n",
    "        goal_difference = goals_scored - goals_conceded\n",
    "        # result = round(1 / (1 + 10**(-goal_difference)))\n",
    "        result = 1 if goal_difference > 0 else 0\n",
    "        if abs(goal_difference) < self.draw_size:\n",
    "            result = 0.5\n",
    "        return result\n",
    "\n",
    "\n",
    "    def predict_data(self, df):\n",
    "        ''' Takes a data frame of home and away teams to predict the number of goals and result of '''\n",
    "        out = df.copy()\n",
    "        for i, row in out.iterrows():\n",
    "            out.at[i, 'EHG'] = self.predict(row['HomeTeam'], row['AwayTeam'])\n",
    "            out.at[i, 'EAG'] = self.predict(row['AwayTeam'], row['HomeTeam'])\n",
    "            out.at[i, 'ER'] = decode_result(self.predict_result(row['HomeTeam'], row['AwayTeam']))\n",
    "        return out\n",
    "\n",
    "    def update_match(self, home, away, home_actual_goals, away_actual_goals):\n",
    "        ''' Updates the offensive and defensive ratings of both teams in a match. '''\n",
    "        home_expected_goals = self.predict(home, away)\n",
    "        away_expected_goals = self.predict(away, home)\n",
    "        self.offensive_ratings[home] += self.learning_rate * (home_actual_goals - home_expected_goals)\n",
    "        self.offensive_ratings[away] += self.learning_rate * (away_actual_goals - away_expected_goals)\n",
    "        self.defensive_ratings[home] += self.learning_rate * (away_expected_goals - away_actual_goals)\n",
    "        self.defensive_ratings[away] += self.learning_rate * (home_expected_goals - home_actual_goals)\n",
    "        self.match_count[home] += 1\n",
    "        self.match_count[away] += 1\n",
    "\n",
    "    def ratings_dataframe(self):\n",
    "        ''' Creates an easy to read dataframe of the ratings '''\n",
    "        df = pd.DataFrame(self.offensive_ratings.items(), columns=['Team', 'Offensive Rating'])\n",
    "        df['Defensive Rating'] = df['Team'].map(self.defensive_ratings)\n",
    "        df['Matches'] = df['Team'].map(self.match_count)\n",
    "        df = df.sort_values('Offensive Rating', ascending=False)\n",
    "        return df\n",
    "\n",
    "    def fit(self, df):\n",
    "        ''' Takes a data frame of matches with columns HomeTeam, AwayTeam, Predicted FTHG, Predicted FTAG and updates teams ratings using the data in order. '''\n",
    "        for i, row in df.iterrows():\n",
    "            if 'Predicted FTHG' in row:\n",
    "                self.update_match(row['HomeTeam'], row['AwayTeam'], row['Predicted FTHG'], row['Predicted FTAG'])\n",
    "            else:\n",
    "                self.update_match(row['HomeTeam'], row['AwayTeam'], row['FTHG'], row['FTAG'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_result(result):\n",
    "    if result == 1:\n",
    "        return 'H'\n",
    "    elif result == 0:\n",
    "        return 'A'\n",
    "    return 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data = pd.read_csv(os.path.join(os.getcwd(), \"output/non_shot_predictions.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = train_test_split(match_data, test_size=0.05, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train elo ratings\n",
    "goal_elo = GoalElo()\n",
    "goal_elo.fit(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto')"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict number of goals for use in training result classifier\n",
    "goal_predicted_data = goal_elo.predict_data(training)\n",
    "\n",
    "X = np.array([goal_predicted_data['EHG'].to_numpy(), goal_predicted_data['EAG'].to_numpy()]).T\n",
    "y = goal_predicted_data['FTR'].to_numpy()\n",
    "# y = [decode_result(r) for r in goal_predicted_data['FTR'].to_numpy()]\n",
    "\n",
    "# Train classifier to predict result from number of goals\n",
    "goal_result_classifier = SVC(gamma='auto')\n",
    "goal_result_classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5058823529411764\n",
      "\n",
      "F1 Score: 0.40906501547987617\n"
     ]
    }
   ],
   "source": [
    "# Predict number of goals scored using goal_elo\n",
    "goal_prediction = goal_elo.predict_data(test)\n",
    "X_test = np.array([goal_prediction['EHG'].to_numpy(), goal_prediction['EAG'].to_numpy()]).T\n",
    "y_test = goal_prediction['FTR'].to_numpy()\n",
    "# Predict result using SVC and elo predicted number of goals\n",
    "y_pred = goal_result_classifier.predict(X_test)\n",
    "# Predict result using piecewise function and elo predicted number of goals\n",
    "y_pred2 = goal_prediction['ER'].to_numpy()\n",
    "\n",
    "# Measure accuracy\n",
    "print(\"Accuracy: {n}\".format(n=accuracy_score(y_test, y_pred)))\n",
    "print()\n",
    "\n",
    "# Measure f1 score\n",
    "print(\"F1 Score: {n}\".format(n=f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final predictions on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, importing the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Newcastle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Everton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Chelsea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Brighton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Man United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Crystal Palace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>Tottenham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>Burnley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>West Brom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date          HomeTeam        AwayTeam\n",
       "0  16 Jan 21           Arsenal       Newcastle\n",
       "1  16 Jan 21       Aston Villa         Everton\n",
       "2  16 Jan 21            Fulham         Chelsea\n",
       "3  16 Jan 21             Leeds        Brighton\n",
       "4  16 Jan 21         Leicester     Southampton\n",
       "5  16 Jan 21         Liverpool      Man United\n",
       "6  16 Jan 21          Man City  Crystal Palace\n",
       "7  16 Jan 21  Sheffield United       Tottenham\n",
       "8  16 Jan 21          West Ham         Burnley\n",
       "9  16 Jan 21            Wolves       West Brom"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data to predict\n",
    "final_test_data = pd.read_csv(os.path.join(os.getcwd(), 'data/epl-test.csv'))\n",
    "final_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ELO Ratings to predict the home and away team goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in final_test_data.iterrows():\n",
    "    final_test_data.at[i, 'HomeGoals'] = goal_elo.predict(teamname_mapping[r['HomeTeam']], teamname_mapping[r['AwayTeam']])\n",
    "    final_test_data.at[i, 'AwayGoals'] = goal_elo.predict(teamname_mapping[r['AwayTeam']], teamname_mapping[r['HomeTeam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HomeGoals</th>\n",
       "      <th>AwayGoals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>1.623105</td>\n",
       "      <td>0.957264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Everton</td>\n",
       "      <td>1.544919</td>\n",
       "      <td>1.488274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>0.984107</td>\n",
       "      <td>2.322189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>1.070574</td>\n",
       "      <td>0.741452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1.441821</td>\n",
       "      <td>1.428890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Man United</td>\n",
       "      <td>1.770880</td>\n",
       "      <td>1.573276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>2.257173</td>\n",
       "      <td>0.729450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>0.839343</td>\n",
       "      <td>1.564277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>1.496072</td>\n",
       "      <td>0.911160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>1.373062</td>\n",
       "      <td>0.645789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date          HomeTeam        AwayTeam  HomeGoals  AwayGoals\n",
       "0  16 Jan 21           Arsenal       Newcastle   1.623105   0.957264\n",
       "1  16 Jan 21       Aston Villa         Everton   1.544919   1.488274\n",
       "2  16 Jan 21            Fulham         Chelsea   0.984107   2.322189\n",
       "3  16 Jan 21             Leeds        Brighton   1.070574   0.741452\n",
       "4  16 Jan 21         Leicester     Southampton   1.441821   1.428890\n",
       "5  16 Jan 21         Liverpool      Man United   1.770880   1.573276\n",
       "6  16 Jan 21          Man City  Crystal Palace   2.257173   0.729450\n",
       "7  16 Jan 21  Sheffield United       Tottenham   0.839343   1.564277\n",
       "8  16 Jan 21          West Ham         Burnley   1.496072   0.911160\n",
       "9  16 Jan 21            Wolves       West Brom   1.373062   0.645789"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the match outcome classifier on the test dataset to generate final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_predictions = np.array([final_test_data['HomeGoals'].to_numpy(), final_test_data['AwayGoals'].to_numpy()]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data['FTR'] = goal_result_classifier.predict(goal_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HomeGoals</th>\n",
       "      <th>AwayGoals</th>\n",
       "      <th>FTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>1.623105</td>\n",
       "      <td>0.957264</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Everton</td>\n",
       "      <td>1.544919</td>\n",
       "      <td>1.488274</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>0.984107</td>\n",
       "      <td>2.322189</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>1.070574</td>\n",
       "      <td>0.741452</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1.441821</td>\n",
       "      <td>1.428890</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Man United</td>\n",
       "      <td>1.770880</td>\n",
       "      <td>1.573276</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>2.257173</td>\n",
       "      <td>0.729450</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>0.839343</td>\n",
       "      <td>1.564277</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>1.496072</td>\n",
       "      <td>0.911160</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16 Jan 21</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>1.373062</td>\n",
       "      <td>0.645789</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date          HomeTeam        AwayTeam  HomeGoals  AwayGoals FTR\n",
       "0  16 Jan 21           Arsenal       Newcastle   1.623105   0.957264   H\n",
       "1  16 Jan 21       Aston Villa         Everton   1.544919   1.488274   H\n",
       "2  16 Jan 21            Fulham         Chelsea   0.984107   2.322189   A\n",
       "3  16 Jan 21             Leeds        Brighton   1.070574   0.741452   H\n",
       "4  16 Jan 21         Leicester     Southampton   1.441821   1.428890   H\n",
       "5  16 Jan 21         Liverpool      Man United   1.770880   1.573276   H\n",
       "6  16 Jan 21          Man City  Crystal Palace   2.257173   0.729450   H\n",
       "7  16 Jan 21  Sheffield United       Tottenham   0.839343   1.564277   A\n",
       "8  16 Jan 21          West Ham         Burnley   1.496072   0.911160   H\n",
       "9  16 Jan 21            Wolves       West Brom   1.373062   0.645789   H"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing results to a [CSV file](./output/final_predictions.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data.to_csv(os.path.join(os.getcwd(), 'output/final_predictions.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
