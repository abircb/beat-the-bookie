{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP0036: Group Coursework \n",
    "\n",
    "## Beat the Bookie\n",
    "\n",
    "`<insert Introduction here>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Python libraries for data and visualisation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Import models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Import error metric\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "#Import data munging tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Display charts in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import\n",
    "``<insert a brief description of our datasets here>``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation and Exploration\n",
    "``<insert a brief description of our preperation and standardisation process here>``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology Overview\n",
    "``Pipeline overview``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and validation\n",
    "\n",
    "#### Shots xG model\n",
    "\n",
    "#### Non-shots xG model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ELO Rating classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalElo:\n",
    "    def __init__(self, initial_rating=0, learning_rate=0.05, draw_size=0.5):\n",
    "        self.offensive_ratings = defaultdict(lambda: initial_rating)\n",
    "        self.defensive_ratings = defaultdict(lambda: initial_rating)\n",
    "        self.match_count = defaultdict(lambda: 0)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.draw_size = draw_size\n",
    "\n",
    "    def predict(self, team, opponent):\n",
    "        ''' Predicts the number of goals team will score against opponent. '''\n",
    "        return self.offensive_ratings[team] - self.defensive_ratings[opponent]\n",
    "\n",
    "    def predict_result(self, team, opponent):\n",
    "        ''' Predicts the result of a match. 1 if team wins, 0 if opponent wins and 0.5 if it is a draw. '''\n",
    "        goals_scored = self.predict(team, opponent)\n",
    "        goals_conceded = self.predict(opponent, team)\n",
    "        return self.classify_result(goals_scored, goals_conceded)\n",
    "\n",
    "    def classify_result(self, goals_scored, goals_conceded):\n",
    "        goal_difference = goals_scored - goals_conceded\n",
    "        # result = round(1 / (1 + 10**(-goal_difference)))\n",
    "        result = 1 if goal_difference > 0 else 0\n",
    "        if abs(goal_difference) < self.draw_size:\n",
    "            result = 0.5\n",
    "        return result\n",
    "\n",
    "\n",
    "    def predict_data(self, df):\n",
    "        ''' Takes a data frame of home and away teams to predict the number of goals and result of '''\n",
    "        out = df.copy()\n",
    "        for i, row in out.iterrows():\n",
    "            out.at[i, 'EHG'] = self.predict(row['HomeTeam'], row['AwayTeam'])\n",
    "            out.at[i, 'EAG'] = self.predict(row['AwayTeam'], row['HomeTeam'])\n",
    "            out.at[i, 'ER'] = decode_result(self.predict_result(row['HomeTeam'], row['AwayTeam']))\n",
    "        return out\n",
    "\n",
    "    def update_match(self, home, away, home_actual_goals, away_actual_goals):\n",
    "        ''' Updates the offensive and defensive ratings of both teams in a match. '''\n",
    "        home_expected_goals = self.predict(home, away)\n",
    "        away_expected_goals = self.predict(away, home)\n",
    "        self.offensive_ratings[home] += self.learning_rate * (home_actual_goals - home_expected_goals)\n",
    "        self.offensive_ratings[away] += self.learning_rate * (away_actual_goals - away_expected_goals)\n",
    "        self.defensive_ratings[home] += self.learning_rate * (away_expected_goals - away_actual_goals)\n",
    "        self.defensive_ratings[away] += self.learning_rate * (home_expected_goals - home_actual_goals)\n",
    "        self.match_count[home] += 1\n",
    "        self.match_count[away] += 1\n",
    "\n",
    "    def ratings_dataframe(self):\n",
    "        ''' Creates an easy to read dataframe of the ratings '''\n",
    "        df = pd.DataFrame(self.offensive_ratings.items(), columns=['Team', 'Offensive Rating'])\n",
    "        df['Defensive Rating'] = df['Team'].map(self.defensive_ratings)\n",
    "        df['Matches'] = df['Team'].map(self.match_count)\n",
    "        df = df.sort_values('Offensive Rating', ascending=False)\n",
    "        return df\n",
    "\n",
    "    def fit(self, df):\n",
    "        ''' Takes a data frame of matches with columns HomeTeam, AwayTeam, Predicted FTHG, Predicted FTAG and updates teams ratings using the data in order. '''\n",
    "        for i, row in df.iterrows():\n",
    "            if 'Predicted FTHG' in row:\n",
    "                self.update_match(row['HomeTeam'], row['AwayTeam'], row['Predicted FTHG'], row['Predicted FTAG'])\n",
    "            else:\n",
    "                self.update_match(row['HomeTeam'], row['AwayTeam'], row['FTHG'], row['FTAG'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train elo ratings\n",
    "goal_elo = GoalElo()\n",
    "goal_elo.fit(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict number of goals for use in training classifier\n",
    "goal_predicted_data = goal_elo.predict_data(training)\n",
    "\n",
    "X = np.array([data['EHG'].to_numpy(), data['EAG'].to_numpy()]).T\n",
    "y = data['FTR'].to_numpy()\n",
    "# y = [decode_result(r) for r in data['FTR'].to_numpy()]\n",
    "\n",
    "goal_result_classifier = SVC(gamma='auto')\n",
    "goal_result_classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_prediction = goal_elo.predict_data(test)\n",
    "X_test = np.array([goal_prediction['EHG'].to_numpy(), goal_prediction['EAG'].to_numpy()]).T\n",
    "y_test = goal_prediction['FTR'].to_numpy()\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred2 = goal_prediction['ER'].to_numpy()\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "print(\"DS: \", accuracy_score(y_test, y_pred2))\n",
    "print(\"SVC: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"F1 Score:\")\n",
    "print(\"DS: \", f1_score(y_test, y_pred2, average='weighted'))\n",
    "print(\"SVC: \", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "``<insert model tests here>``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
